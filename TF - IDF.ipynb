{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is TF-IDF in Machine Learning?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important ways to resize data in the machine learning process is to use the term frequency inverted document frequency, also known as the tf-idf method.\n",
    "\n",
    "## What is tf-idf?\n",
    "The intuition of the tf-idf method is to give high weight to any term that often appears in a particular document, but not in many documents in the corpus. If a word appears often in a particular document, but not in many documents, it is likely to be very descriptive of the contents of that document.\n",
    "\n",
    "## Why Use Tf-Idf Vectorization?\n",
    "Suppose a search engine has a database with thousands of cat descriptions and a user wants to search for furry cats, then he/she issues the query “furry cat”. A search engine needs to decide which result should be returned from the database.\n",
    "\n",
    "If the search engine has documents that match the exact query, there is no doubt, but what if it needs to decide between partial matches? To simplify, let’s say it has to choose between these two descriptions:\n",
    "\n",
    "“The pretty cat”\n",
    "“A furry kitten”\n",
    "The first description contains 2 of 3 words of the query and the second only matches 1 of 3, then the search engine will choose the first description. How can TF-IDF help it to choose the second description instead of the first?\n",
    "\n",
    "The TF is the same for every word, no difference here. However, one would expect the terms “cat” and “kitten” to appear in many documents (high frequency of documents implies low IDF), while the term “furry” will appear in fewer documents (IDF taller). Thus, the TF-IDF for cat & kitten has a low value while the TF-IDF is larger for “hairy”, that is to say, that in our database the word “hairy” has more power. discriminating as “cat” or “kitten”.\n",
    "\n",
    "If we use the TF-IDF to weight the different words that match the query, “hairy” would be more relevant than “cat” and so we could choose “hairy kitten” as the best match."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation with Python\n",
    "Now let’s see how to implement the tf-idf method with Machine Learning using the Python programming language. The example below shows the implementation of tf-idf vectorization using Scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n",
      "(4, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that tf-idf scaling is intended to find words that distinguish documents, but this is a purely unsupervised technique. Low tf-idf features are those that are either very commonly used in documents or used sparingly and only in very long documents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "d3248654ea22e01eba30be24c737f166101737355c2d9a9058a779190f8245d1"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
