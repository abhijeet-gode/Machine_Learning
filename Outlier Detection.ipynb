{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An outlier is a terminology commonly used by analysts and data scientists because it requires special attention, otherwise, it can lead to totally wrong estimates.\n",
    "Simply put, outlier detection is an observation that appears far away from and diverges from an overall pattern in a sample."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is Outlier?\n",
    "An outlier is an observation that is numerically distant from the rest of the data or, in a nutshell, is the value that is out of range. Letâ€™s take an example to check what happens to a dataset with a dataset without outliers.\n",
    "\n",
    "\t                  Data without Outliers\t   |       Data with Outliers\n",
    "- Data\t               1, 2, 3, 3, 4, 5, 4\t   |    1, 2, 3, 3, 4, 5, 400\n",
    "- Mean\t                     3.142\t           |          59.714\n",
    "- Median\t                   3\t           |            3\n",
    "- Standard Deviation\t     1.345185\t       |         150.057"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the dataset with outliers has a significantly different mean and standard deviation. In the first scenario, we will say that the average is 3.14. But with the outlier, the average climbs to 59.71. This would completely change the estimate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s take a concrete example of an outlier. In a company of 50 employees, 45 people with a monthly salary of Rs. 6000, 5 seniors with a monthly salary of Rs. 100000 each. If you calculate the average monthly salary of the employees of the company is 14,500 rupees, which will give you a bad conclusion.\n",
    "\n",
    "But if you take the median salary, it is Rs.6000 which is more sensitive than the average. For this reason, the median is an appropriate measure for the mean. Here you can see the effect of an outlier.\n",
    "\n",
    "Now letâ€™s have a quick look at the main causes of outliers before getting started with the task of outlier detection:\n",
    "\n",
    "- Data Entry Errors: Human errors such as errors caused during data collection, recording, or entry can cause outliers in data.\n",
    "- Measurement Errors: It is the most common source of outliers. This is caused when the measurement instrument used turns out to be faulty.\n",
    "- Natural Outliers: When an outlier is not artificial (due to error), it is a natural outlier. Most real-world data belong to this category.\n",
    "\n",
    "## Outlier Detection in Machine Learning using Hypothesis Testing\n",
    "Now, An outlier can be of two types: Univariate and Multivariate. Above, we have discussed the example of a univariate outlier. These outliers can be found when we look at the distribution of a single variable. Multivariate outliers are outliers in an n-dimensional space.\n",
    "\n",
    "Hypothesis testing is a common technique for detecting outliers in machine learning. Hypothesis testing is a method of testing a claim or hypothesis about a parameter in a population, using data measured in a sample. In this method, we test a hypothesis by determining the probability that a sample statistic could have been selected, if the hypothesis regarding the population parameter was true.\n",
    "\n",
    "The purpose of the hypothesis test is to determine the probability that a population parameter, such as the mean, is likely to be true. There are four steps in the hypothesis test:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State the assumptions.\n",
    "Define the criteria for a decision.\n",
    "Calculate the test statistic.\n",
    "Make a decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H_test Calculated Value: 1.4274928542926593\n",
      "H_test Critical Value: 1.887145117792422\n",
      "From H_test we observe that calculated value is lesser than critical value, Accept null hypothesis and conclude that there is no outliers\n",
      "\n",
      "H_test Calculated Value: 2.2765147221587774\n",
      "H_test Critical Value: 2.019968507680656\n",
      "From H_test we observe that calculated value is greater than critical value, Reject null hypothesis and conclude that there is an outliers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "x = np.array([12,13,14,19,21,23])\n",
    "\n",
    "y = np.array([12,13,14,19,21,23,45])\n",
    "\n",
    "def H_test(x):\n",
    "    n = len(x)\n",
    "    mean_x = np.mean(x)\n",
    "    sd_x = np.std(x)\n",
    "    numerator = max(abs(x-mean_x))\n",
    "    g_calculated = numerator/sd_x\n",
    "    \n",
    "    print(\"H_test Calculated Value:\",g_calculated)\n",
    "    \n",
    "    t_value = stats.t.ppf(1 - 0.05 / (2 * n), n - 2)\n",
    "    g_critical = ((n - 1) * np.sqrt(np.square(t_value))) / (np.sqrt(n) * np.sqrt(n - 2 + np.square(t_value)))\n",
    "    \n",
    "    print(\"H_test Critical Value:\",g_critical)\n",
    "    \n",
    "    if g_critical > g_calculated:\n",
    "        print(\"From H_test we observe that calculated value is lesser than critical value, Accept null hypothesis and conclude that there is no outliers\\n\")\n",
    "    else:\n",
    "        print(\"From H_test we observe that calculated value is greater than critical value, Reject null hypothesis and conclude that there is an outliers\\n\")\n",
    "H_test(x)\n",
    "H_test(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the major problems with machine learning is an outlier. If you will neglect the outliers in the data, then it will result in the poor performance of your machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -1.  54.  77.  53.  43.  32.  12.  22.  31. 420.] \n",
      "\n",
      "Mean for Data: 74.3\n",
      "Median for Data: 37.5\n",
      "Standard Deviation for Data: 117.18024577547189\n"
     ]
    }
   ],
   "source": [
    "# IQR For Outlier Treatment\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "data = np.array([-1,54,77,53,43,32,12,22,31,420], dtype='float')\n",
    "print(data, '\\n')\n",
    "print(f\"Mean for Data: {np.mean(data)}\")\n",
    "print(f\"Median for Data: {np.median(data)}\")\n",
    "print(f\"Standard Deviation for Data: {np.std(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.  54.  77.  53.  43.  32.  12.  22.  31.  37.5] \n",
      "\n",
      "Mean for Data: 36.05\n",
      "Median for Data: 34.75\n",
      "Standard Deviation for Data: 21.277276611446307\n"
     ]
    }
   ],
   "source": [
    "q1 = np.percentile(data, 25)\n",
    "q3 = np.percentile(data, 75)\n",
    "IQR = q3 - q1\n",
    "\n",
    "upper = q3 + 1.5 * IQR\n",
    "lower = q1 - 1.5 * IQR\n",
    "\n",
    "outlier = (data>upper) | (data<lower)\n",
    "data[outlier] = np.median(data)\n",
    "print(data,'\\n')\n",
    "print(f\"Mean for Data: {np.mean(data)}\")\n",
    "print(f\"Median for Data: {np.median(data)}\")\n",
    "print(f\"Standard Deviation for Data: {np.std(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -1.  54.  77.  53.  43.  32.  12.  22.  31. 420.]\n",
      "74.3\n",
      "117.18024577547189 \n",
      "\n",
      "[-0.6425997786715836, -0.17323739053164866, 0.023041426326869553, -0.18177125213419293, -0.2671098681596356, -0.3609823457876226, -0.531659577838508, -0.4463209618130653, -0.3695162073901669, 2.9501559559995543]\n",
      "4.4408920985006264e-17\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Standadization\n",
    "\n",
    "print(data := np.array([-1,54,77,53,43,32,12,22,31,420], dtype='float'))\n",
    "print(meann := np.mean(data))\n",
    "print(stdd := np.std(data),'\\n')\n",
    "\n",
    "z = [(x-meann)/stdd for x in data]\n",
    "print(z)\n",
    "\n",
    "print(meann := np.mean(z))\n",
    "print(stdd := np.std(z))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "d3248654ea22e01eba30be24c737f166101737355c2d9a9058a779190f8245d1"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
